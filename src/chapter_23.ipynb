{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "ca55fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 23: Processing Multiple Files Automatically\n",
    "\n",
    "⚠️ **DO NOT SKIP THIS CELL**\n",
    "\n",
    "## Run the Next cell.\n",
    "### Before executing any other cell you must run the next cell to set up the project folder environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c612eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    drive.mount(\"/content/drive\")\n",
    "    PROJECT_ROOT = Path(\"/content/drive/MyDrive/DataScience/census-education-analysis\")\n",
    "else:\n",
    "    PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "STAGING_DIR = DATA_DIR / \"staging\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "OUTPUTS_DIR = PROJECT_ROOT / \"outputs\"\n",
    "\n",
    "PROJECT_ROOT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "4a255adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 1: Where Are the Input Files for Batch Processing?"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "9d833753",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 2: How Do We Locate All State Files Programmatically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaceeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "staging_edu_dir = STAGING_DIR / \"education\"\n",
    "state_files = list(staging_edu_dir.glob(\"*.xlsx\"))\n",
    "\n",
    "len(state_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "51e15c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 3: What ETL Logic Are We Reusing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fa5021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_staged_excel(file_path):\n",
    "    \"\"\"\n",
    "    Load a renamed Census education Excel file from staging.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(file_path, skiprows=7, header=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac196c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_census_data(df):\n",
    "    \"\"\"\n",
    "    Select required columns, rename them,\n",
    "    clean text fields, and filter to 'all ages'.\n",
    "    \"\"\"\n",
    "    edu_selected = df.iloc[:, [\n",
    "        2,   # District Code\n",
    "        4,   # Area Type\n",
    "        5,   # Age Group\n",
    "        6,   # Total Persons\n",
    "        7,   # Male Persons\n",
    "        8,   # Female Persons\n",
    "        9,   # Total Illiterate\n",
    "        10,  # Male Illiterate\n",
    "        11,  # Female Illiterate\n",
    "        12,  # Total Literate\n",
    "        13,  # Male Literate\n",
    "        14   # Female Literate\n",
    "    ]].copy()\n",
    "\n",
    "    edu_selected.columns = [\n",
    "        \"district_code\",\n",
    "        \"area_type\",\n",
    "        \"age_group\",\n",
    "        \"total_persons\",\n",
    "        \"male_persons\",\n",
    "        \"female_persons\",\n",
    "        \"total_illiterate\",\n",
    "        \"male_illiterate\",\n",
    "        \"female_illiterate\",\n",
    "        \"total_literate\",\n",
    "        \"male_literate\",\n",
    "        \"female_literate\",\n",
    "    ]\n",
    "\n",
    "\n",
    "    edu_selected[\"age_group\"] = (\n",
    "        edu_selected[\"age_group\"]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "    )\n",
    "\n",
    "    edu_selected[\"area_type\"] = (\n",
    "        edu_selected[\"area_type\"]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "    )\n",
    "\n",
    "    # Remove rows that do not represent real geographic data\n",
    "    edu_selected = edu_selected[edu_selected[\"district_code\"].notna()]\n",
    "\n",
    "    # Standard cleaning steps\n",
    "    edu_selected[\"district_code\"] = edu_selected[\"district_code\"].astype(int)\n",
    "\n",
    "    # Clean column labels (defensive, even if already renamed)\n",
    "    edu_selected.columns = edu_selected.columns.str.strip()\n",
    "\n",
    "    # Replace missing numeric values with 0\n",
    "    edu_selected = edu_selected.fillna(0)\n",
    "\n",
    "    # Keep only \"all ages\"\n",
    "    edu_selected = edu_selected[edu_selected[\"age_group\"] == \"all ages\"]\n",
    "\n",
    "    return edu_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c0ce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_census_data(df):\n",
    "    \"\"\"\n",
    "    Validate numeric consistency of Census counts.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    df[\"persons_check\"] = (\n",
    "        df[\"male_persons\"] + df[\"female_persons\"] - df[\"total_persons\"]\n",
    "    )\n",
    "\n",
    "    df[\"illiterate_check\"] = (\n",
    "        df[\"male_illiterate\"] + df[\"female_illiterate\"] - df[\"total_illiterate\"]\n",
    "    )\n",
    "\n",
    "    df[\"literate_check\"] = (\n",
    "        df[\"male_literate\"] + df[\"female_literate\"] - df[\"total_literate\"]\n",
    "    )\n",
    "\n",
    "    df[\"is_valid\"] = (\n",
    "        (df[\"persons_check\"] == 0) &\n",
    "        (df[\"illiterate_check\"] == 0) &\n",
    "        (df[\"literate_check\"] == 0)\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062aaa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def census_etl_pipeline(excel_path):\n",
    "    \"\"\"\n",
    "    Full ETL pipeline for one Census education Excel file.\n",
    "    \"\"\"\n",
    "    df_raw = load_staged_excel(excel_path)\n",
    "    df_cleaned = clean_census_data(df_raw)\n",
    "    df_validated = validate_census_data(df_cleaned)\n",
    "    return df_validated"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "19f903a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 4: How Do I Process One File Inside a Loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462a4fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(PROCESSED_DIR / \"education\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "processed_files = []\n",
    "\n",
    "for file_path in state_files:\n",
    "    # Print progress so you know what the computer is doing\n",
    "    print(f\"Processing: {file_path.name}...\")\n",
    "\n",
    "    # Apply the full ETL pipeline (clean + validate)\n",
    "    edu_df = census_etl_pipeline(file_path)\n",
    "\n",
    "    # Build output filename\n",
    "    output_name = file_path.stem + \"_processed.csv\"\n",
    "    output_path = PROCESSED_DIR / \"education\" / output_name\n",
    "\n",
    "    # Save result\n",
    "    edu_df.to_csv(output_path, index=False)\n",
    "\n",
    "    processed_files.append(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "1faeaadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 5: How Do I Verify That All States Were Processed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1410ad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(processed_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a46f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = processed_files[0]\n",
    "sample_df = pd.read_csv(sample_path)\n",
    "\n",
    "sample_df.shape\n",
    "sample_df[\"is_valid\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "48eac49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 6: Why Do We Save One CSV per State?"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "225f441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 7: What Mistakes Does Automation Prevent?"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "0b65171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 8: What Exactly Have We Produced?"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "91fa47b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## End-of-Chapter Direction"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
