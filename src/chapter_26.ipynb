{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "9ac0843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 26: Gender-Based Education Analysis\n",
    "\n",
    "⚠️ **DO NOT SKIP THIS CELL**\n",
    "\n",
    "## Run the Next cell.\n",
    "### Before executing any other cell you must run the next cell to set up the project folder environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe5e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    drive.mount(\"/content/drive\")\n",
    "    PROJECT_ROOT = Path(\"/content/drive/MyDrive/DataScience/census-education-analysis\")\n",
    "else:\n",
    "    PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "STAGING_DIR = DATA_DIR / \"staging\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "OUTPUTS_DIR = PROJECT_ROOT / \"outputs\"\n",
    "\n",
    "PROJECT_ROOT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "d42c2be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 1: What Data Are We Starting With?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f3c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "india_path = PROCESSED_DIR / \"india_literacy.csv\"\n",
    "india_df = pd.read_csv(india_path)\n",
    "\n",
    "india_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "bd18f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 2: Why Are Raw Literacy Counts Misleading for Gender Analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "73e7bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 3: Which Rows Should Be Used for Gender Analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b4491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df = india_df[india_df[\"area_type\"] == \"total\"].copy()\n",
    "gender_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "2b13d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 4: What Basic Numbers Do We Already Have?"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "ec8231b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 5: How Do We Compute Male and Female Literacy Rates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87c8814",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df[\"male_literacy_rate\"] = (\n",
    "    gender_df[\"male_literate\"] / gender_df[\"male_persons\"]\n",
    ")\n",
    "\n",
    "gender_df[\"female_literacy_rate\"] = (\n",
    "    gender_df[\"female_literate\"] / gender_df[\"female_persons\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "9dd3efed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 6: How Do We Measure the Gender Literacy Gap Directly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e230606",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df[\"gender_literacy_gap\"] = (\n",
    "    gender_df[\"male_literacy_rate\"] -\n",
    "    gender_df[\"female_literacy_rate\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "b371e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 7: How Do We Summarize Gender Inequality at the State Level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2d72cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_gender_gap = (\n",
    "    gender_df\n",
    "    .groupby(\"state_name\")[\"gender_literacy_gap\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values(\"gender_literacy_gap\", ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "72db8370",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 8: How Do We Sanity-Check These Results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883eaaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_gender_gap.head()\n",
    "state_gender_gap.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "4d4400e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 9: How Do We Save Gender Metrics for the Next Chapter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15525cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_output_path = PROCESSED_DIR / \"india_gender_metrics.csv\"\n",
    "gender_df.to_csv(gender_output_path, index=False)\n",
    "\n",
    "gender_output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "a59fd893",
   "metadata": {},
   "outputs": [],
   "source": [
    "## End-of-Chapter Direction"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
